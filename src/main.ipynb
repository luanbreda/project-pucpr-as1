{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0c4e7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg,max,min,sum, udf, col, when, count, round, concat_ws, lit, first\n",
    "from pyspark.sql.types import StringType, IntegerType, FloatType, StructType, StructField\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Window\n",
    "import os\n",
    "import unicodedata\n",
    "import inspect\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(\"../src\"))  # Adiciona src ao caminho\n",
    "\n",
    "from funcao import remove_acentos\n",
    "\n",
    "spark = SparkSession.builder.appName(\"NotasPorMateriaEAluno\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "105875dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_acentos_udf = udf(remove_acentos, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d126c2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----+\n",
      "| aluno|       mat|nota|\n",
      "+------+----------+----+\n",
      "|  João|Matemática|   8|\n",
      "|  João|Matemática|   9|\n",
      "| Maria|  História|   7|\n",
      "| Maria|  História|   6|\n",
      "| Pedro|  Ciências|  10|\n",
      "| Pedro|  Ciências|   8|\n",
      "|   Ana|Matemática|   9|\n",
      "|   Ana|  História|   8|\n",
      "|   Ana|  Ciências|   7|\n",
      "|Carlos|Matemática|   6|\n",
      "|Carlos|  História|   5|\n",
      "|Carlos|  Ciências|   4|\n",
      "+------+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(\"João\", \"Matemática\", 8), (\"João\", \"Matemática\", 9), \n",
    "        (\"Maria\", \"História\", 7), (\"Maria\", \"História\", 6), \n",
    "        (\"Pedro\", \"Ciências\", 10), (\"Pedro\", \"Ciências\", 8),\n",
    "        (\"Ana\", \"Matemática\", 9), (\"Ana\", \"História\", 8), \n",
    "        (\"Ana\", \"Ciências\", 7), (\"Carlos\", \"Matemática\", 6), \n",
    "        (\"Carlos\", \"História\", 5), (\"Carlos\", \"Ciências\", 4)]\n",
    "\n",
    "df = spark.createDataFrame(data, [\"aluno\", \"mat\", \"nota\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3952b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_unifica_linhas = (\n",
    "    df\n",
    "    .withColumn(\"mat_sem_acentos\", remove_acentos_udf(col(\"mat\")))\n",
    "    .groupBy(col(\"aluno\"))\n",
    "    .pivot(\"mat_sem_acentos\")\n",
    "    .agg(first(col(\"nota\")))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ee22805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+--------+----------+\n",
      "| aluno|Ciencias|Historia|Matematica|\n",
      "+------+--------+--------+----------+\n",
      "|Carlos|       4|       5|         6|\n",
      "|  João|       0|       0|         8|\n",
      "| Pedro|      10|       0|         0|\n",
      "|   Ana|       7|       8|         9|\n",
      "| Maria|       0|       7|         0|\n",
      "+------+--------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_2 = (\n",
    "    df_unifica_linhas\n",
    "    .fillna(0, subset=[\"Matematica\", \"Historia\", \"Ciencias\"])\n",
    ")\n",
    "df_2.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
